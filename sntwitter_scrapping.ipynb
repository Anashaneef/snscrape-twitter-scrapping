{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import re\n",
    "from cleantext import clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_18720\\277455601.py:14: DeprecatedFeatureWarning: content is deprecated, use rawContent instead\n",
      "  content = tweet.content.split()\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_18720\\277455601.py:17: DeprecatedFeatureWarning: content is deprecated, use rawContent instead\n",
      "  clean_tweet = clean(tweet.content, no_emoji=True)\n",
      "Stopping after 20 empty pages\n"
     ]
    }
   ],
   "source": [
    "# Keyword & date range\n",
    "query = \"russian inflation until:2023-05-05 since:2023-01-01\"\n",
    "tweets = []\n",
    "# Maximum tweets to be scraped\n",
    "limit = 10\n",
    "# keyword check, because some tweet may be don't have the keyword that we want\n",
    "check = \"inflation\"\n",
    "\n",
    "\n",
    "for i, tweet in enumerate(sntwitter.TwitterSearchScraper(query).get_items()):\n",
    "    if len(tweets) == limit:\n",
    "        break\n",
    "    else :\n",
    "        content = tweet.content.split()\n",
    "        if check in content:\n",
    "            # remove emoji\n",
    "            clean_tweet = clean(tweet.content, no_emoji=True)\n",
    "            # remove line break\n",
    "            clean_tweet = clean_tweet.replace(\"\\n\", \" \")\n",
    "            # remove hashtag\n",
    "            clean_tweet = re.sub(r\"#(\\w+)\", \"\", clean_tweet)\n",
    "            # remove annoying data\n",
    "            clean_tweet = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", clean_tweet)\n",
    "            # remove whitespace\n",
    "            clean_tweet = \" \".join(clean_tweet.split())\n",
    "            # just use the tweet and date\n",
    "            tweets.append([tweet.date, clean_tweet])\n",
    "\n",
    "df = pd.DataFrame(tweets, columns=['date', 'tweet'])\n",
    "# cleaning the remaining dirty tweets\n",
    "tweets_clean = df['tweet'].apply(lambda x: clean(x, fix_unicode=True, to_ascii=True, lower=True, no_line_breaks=True, no_urls=True, no_emails=True, no_phone_numbers=True, no_currency_symbols=True, no_punct=True, replace_with_url=\"\", replace_with_email=\"\", replace_with_phone_number=\"\", replace_with_currency_symbol=\"\"))\n",
    "\n",
    "# combine date and tweet\n",
    "tweet_fix = pd.concat([df['date'], tweets_clean], axis=1)\n",
    "\n",
    "# remove duplicate tweets\n",
    "tweet_fix = tweet_fix.drop_duplicates(subset=['tweet'], keep='first')\n",
    "\n",
    "# save to csv\n",
    "tweet_fix.to_csv('./data/russian_inflation.csv', index=False, header=['date', 'tweet'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
